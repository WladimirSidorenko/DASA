% \done[inline]{\newcite{Bickerstaffe:10}}

% \newcite{Bickerstaffe:10} also considered the rating prediction task,
% addressing this problem with the minimum-spanning-tree (MST) SVM
% approach.  In the initial step of this method, they constructed a
% strongly connected graph whose vertices were associated with the most
% representative example (determined via the average all-pairs Tanimoto
% coefficient) of each star rating and the edge weights represented the
% Tanimoto distances between those nodes.  Afterwards, they determined
% the MST of this graph using the Kruskal's
% algorithm~\cite[see][pp.~567--574]{Cormen:09} and, finally,
% constructed a decision tree from this MST, replacing the MST vertices
% with binary SVM classifiers, which had to discern the respective
% rating groups. An evaluation on the four-star review corpus
% of~\newcite{Pang:05} showed an improvement by up to~7\% over the
% previous state of the art, boosting it to 59.37\% average accuracy.

In principle, the importance of discourse phenomena for classifying
text polarity was recognized from the outset of sentiment research.
In their work on movie reviews, \newcite{Pang:02} realized that 
the effct of polarity clues could any time be
reversed by a single counter-argument of the critic (see
Example~\ref{disc-snt:exmp-pang02}).  Confirming this, \newcite{Polanyi:06} ranked discourse relations among
the most important factors that could significantly influence the
intensity and polarity of a sentiment, using different effects of concessions and elaborations as examples. 

\newcite{Pang:04} were among the first who in fact incorporated a
discourse-aware component into a document-level sentiment classifier.
In their two-stage system, the first
predictor distinguished between subjective and objective statements, and the second 
inferred the text polarity by regarding only
sentences from the subjective.  With this method,
they achieved a statistically significant improvement
(86.2\% versus 85.2\% for the Na\"{\i}ve Bayes system and 86.15\%
versus 85.45\% for SVM) over classifiers that analyzed all text
sentences at once, without any filtering.
%% (Later on, a similar approach was also proposed by
%% \newcite{Yessenalina:10}~[\citeyear{Yessenalina:10}], who used
%% an expectation-maximization algorithm to select a small subset of
%% the most indicative sentences and then classified the document [as
%% either positive or negative] with the help of this subset,
%% achieving 93.22\% accuracy on the aforementioned IMDB dataset.)
%Although an oversimplification, the core idea that locally adjacent
%sentences are likely to share the same subjective orientation
%(\emph{local coherence}) was dominating the following DASA research
%for almost a decade.  For example, 
Around the same time, \newcite{Riloff:03}  improved the
accuracy of their Na\"{\i}ve Bayes predictor of subjective expressions
by almost two percent after adding local coherence features, similar to 
\newcite{Hu:04}, who took the semantic orientation of
previous context into account for classifying a sentence.

A little later, another line of research
concentrated on the joint classification of all opinions in the text,
where in addition to predicting each sentiment in isolation, the
authors also sought to maximize the ``total happiness'' (\emph{global
  coherence}) of these assignments. We mention here 
% ensuring that related subjective
%statements received agreeing polarity scores.  Notable works in this
%direction were done by \newcite{Snyder:07}, who proposed the Good Grief
%algorithm for predicting users' satisfaction with different restaurant
%aspects, and 
\newcite{Somasundaran:08a,Somasundaran:08}, who introduced
the concept of \emph{opinion frames} (OF), a special data structure
for capturing the relations between opinions in discourse.  
%Depending
%on the type of these opinions (arguing~[\emph{A}] or
%sentiment~[\emph{S}]), their polarity towards the target
%(positive~[\emph{P}] or negative~[\emph{N}]), and semantic
%relationship between these targets (alternative~[\emph{Alt}] or the
%same~[\emph{same}]), the authors distinguished 32 types of possible
%frames (\emph{SPSPsame}, \emph{SPSNsame}, \emph{APAPalt}, etc.),
%dividing them into reinforcing and non-reinforcing ones.  In later
%works, \newcite{Somasundaran:09a,Somasundaran:09b} also presented two
%joint inference frameworks (one based on the iterative classification
%and another one relying on integer linear programming) for determining
%the best configuration of all frames in text, achieving 77.72\%
%accuracy on frame prediction in the AMI meeting
%corpus~\cite{Carletta:05}.
%% \done[inline]{\newcite{Somasundaran:09a,Somasundaran:09b}}
%% In a later work, \newcite{Somasundaran:09b,Somasundaran:09a} also
%% introduced a joint inference framework based on the Iterative
%% Classification Algorithm (ICA) and Integer Linear Programming (ILP)
%% for joinly predicting the best configuration of single opinions and
%% their frames.  In this approach, the authors first applied a local SVM
%% classifier to compute the probabilities of polarity classes (positive,
%% negative, or neutral) of individual dialog acts and then harnessed the
%% ICA and ILP systems to determine which of the predicted opinions were
%% connected via opinion frames and whether these frames were reinforcing
%% or not.  Given a perfect information about the opinion links, this
%% joint method outperformed the local classifier by more than 9
%% percentage points, reaching 77.72\% accuracy on the AMI meeting
%% corpus~\cite{Carletta:05}.
%% \done[inline]{\newcite{Mao:06}}
%% \newcite{Mao:06} proposed the idea of isotonic CRFs in which they
%% explicitly modeled the constraint that features which were stronger
%% associated with either polarity classes had to have higher
%% coefficients than less predictive attributes.  After proving that this
%% formalism also allowed to directly model the ordinal scale of
%% sentiment scores (with lower CRF outputs indicating the negativity of
%% a sentence, and higher scores showing its positive class), the authors
%% used this approach to model the sentiment flow in a document.  For
%% this purpose, they first predicted the polarity value for each
%% sentence of a document in isolation and then convolved these outputs
%% with a Gaussian kernel, getting a smoothed polarity curve for the
%% whole analyzed text at the end.
%% \done[inline]{\newcite{Thomas:06}}
%% \newcite{Thomas:06} enhanced an SVM-based sentiment classification
%% system for predicting speaker's attitude in political speeches with
%% information about the inter-speaker agreement, incorporating these
%% links into the global cost function.  Thanks to this change, the
%% authors achieved $\approx$4\% improvement in accuracy (from 66.05 to
%% 70.81\%) over the baseline classifer which analyzed each utterance in
%% isolation.
A related idea was proposed by
\newcite{McDonald:07}, who tried to simultaneously predict the polarity
of a document and classify semantic orientations of its sentences.
For this purpose, the authors devised an undirected probabilistic
graphical model based on the structured linear
classifier~\cite{Collins:02}.  Similarly to \newcite{Pang:04}, they
connected the label nodes of each sentence to the labels of its
neighboring clauses and also linked these nodes to the overarching
vertex representing the polarity of the text.  
%After optimizing this
%model with the MIRA learning algorithm~\cite{Crammer:03},
This lead to an accuracy of 82.2\% for
document-level classification and 62.6\% for sentence-level prediction
on a corpus of online product reviews, outperforming pure document and
sentence classifiers by up to four percent.  A crucial limitation of
this system, however, was that its optimization required the gold labels
of sentences and documents to be known at the training time.
%which
%considerably limited its applicability to other domains with no such
%data.

%% A similar approach was also suggested by~\newcite{Sadamitsu:08}, who
%% attained 82.74\% accuracy on predicting the polarity of customer
%% reviews with the help of hidden conditional random fields.

An early attempt at integrating dedicated discourse structure
knowledge (inspired by RST) was made by \newcite{Voll:07}, who enhanced
their lexicon-based sentiment calculator (SO-CAL).  In the first
method, SO-CAL analyzed only the topmost nucleus EDU of each sentence,
whereas in the second approach, the input comprised all clauses
that another classifier had considered as relevant to the main topic
of the document.  While the first idea yielded a mere 69\% accuracy on
the corpus of Epinion reviews~\cite{Taboada:06}, the second achieved
73\% on this two-class prediction task.

Along the same lines, \newcite{Heerschop:11} experimented with increasing the polarity scores of words that appeared near the
  end of the document; assigning higher weights to nucleus tokens; and  learning separate scores for nuclei and satellites using a genetic algorithm.
%An evaluation of these methods on the movie review corpus
%of~\newcite{Pang:04} showed better performance of the first option
%(60.8\% accuracy and 0.597 macro-\F), but the authors could
%significantly improve the results of the last classifier at the end by
%adding an offset to the decision boundary of this method, which
%increased both its accuracy and macro-averaged \F{} to 0.72.
Similarly, \newcite{Zhou:11} used a set of heuristic rules to infer
polarity shifts of discourse units based on their nuclearity status
and outgoing relation links; \newcite{Zirn:11} used a lexicon-based
sentiment system to predict the polarity scores of elementary
discourse units and then enforced consistency of these assignments
over the RST tree with the help of Markov logic constraints; and
\newcite{Wang:13} determined the
document score by taking a linear combination of the polarity scores of its
EDUs and multiplying these scores with automatically learned
coefficients.

%% \footnote{Similarly to the approach of~\newcite{Zirn:11}, these
%%   coefficients depended on the status of the segment in the RST
%%   tree (whether nucleus or sattelite) and relation, which connected
%%   the respective discourse node to the ancestor.}  A similar system
%%   was also described by \newcite{Chenlo:13,Chenlo:14}, who used their
%%   model to analyze user blog posts, achieving significantly better
%%   results on the TREC corpus \cite{Macdonald:09} than any
%%   discourse-unaware baselines.

Among the recent advances in RST-aware sentiment research, we
emphasize the work of \newcite{Bhatia:15}, who
proposed the two methods of discourse-depth reweighting (DDR)
 and rhetorical recursive neural network (R2N2).
For DDR, the authors estimated the relevance of an EDU using its depth in the tree and computed its sentiment score with the polarity scores of its unigrams.
%$\lambda_i$ of each elementary discourse unit $i$ as:
%\begin{equation*}
%  \lambda_i = \max\left(0.5, 1 - d_i/6\right),
%\end{equation*}
%where $d_i$ stands for the depth of the $i$-th EDU in the document's
%discourse tree.  Afterwards, they computed the sentiment score
%$\sigma_i$ of that unit by taking the dot product of its binary
%feature vector $\mathbf{w}_i$ (token unigrams) with polarity scores
%$\boldsymbol{\theta}$ of these unigrams:
%\begin{equation*}
%  \sigma_i = \boldsymbol{\theta}^{\top}\mathbf{w}_i;
%\end{equation*}
The overall 
document score is the sum of sentiment scores for all EDUs,
multiplied with their respective depth factors.
%\begin{equation*}
%  \Psi = \sum_i\lambda_i\boldsymbol{\theta}^T\mathbf{w}_i = \boldsymbol{\theta}^T\%sum_i\lambda_i\mathbf{w}_i,
%\end{equation*}
The R2N2 system largely adopts the RNN method
of~\newcite{Socher:13} by recursively computing the polarity scores of
discourse units.
%\begin{equation*}
%  \psi_i = \tanh\left(K_n^{(r_i)} \psi_{n(i)} + K_s^{(r_i)}\psi_{s(i)} \right),
%\end{equation*}
%where $K_n^{(r_i)}$ and $K_s^{(r_i)}$ stand for the nucleus and
%satellite coefficients associated with the rhetorical relation $r_i$,
%and $\psi_{n(i)}$ and $\psi_{s(i)}$ represent sentiment scores of the
%nucleus and satellite of the $i$-th vertex.  
This approach achieved
84.1\% two-class accuracy on the movie review corpus
of~\newcite{Pang:04} and reached 85.6\% on the dataset
of~\newcite{Socher:13}.

Using the PDTB approach to discourse representation, \newcite{Trivedi:13} proposed a method based on latent
structural SVM~\cite{Yu:09}, where they represented each sentence as a
vector of features produced by a feature function $\mathbf{f}(y,
\mathbf{x}_i, h_i)$, in which $y\in\{-1, +1\}$ denotes the potential
polarity of the whole document, $h_i \in \{0, 1\}$ stands for the
assumed subjectivity class of sentence $i$, and $\mathbf{x}_i$
represents the surface form of that sentence; and then tried to infer
the most likely semantic orientation of the document $\hat{y}$ over
all possible assignments $\mathbf{h}$, \ie{}:
\begin{equation*}
  \hat{y} =
  \argmax_y\left(\max_{\mathbf{h}}\mathbf{w}^{\top}\mathbf{f}(y,
  \mathbf{x}, \mathbf{h})\right).
\end{equation*}
To ensure that these assignments were still coherent, the authors
additionally extended their feature space with special
\emph{transitional} attributes, which indicated whether two adjacent
sentences were likely to share the same subjectivity given the
discourse connective between them.  With the help of these features,
\newcite{Trivedi:13} could improve the accuracy of the
connector-unaware model on the movie review corpus of~\newcite{Maas:11}
from 88.21 to 91.36\%.

Sentiment has also been studied with the SDRT framework, viz.\ by
\newcite{Asher:08}, who presented an annotation scheme and a pilot
corpus of English and French texts. Annotators 
assigned one of four
opinion categories (reporting, judgment, advice, or sentiment) along
with their subclasses (\eg{} inform, assert, blame, recommend) to each
discourse unit that had at least one opinionated word from a sentiment
lexicon.  Then the authors showed that with a simple set of rules, one
could easily propagate opinions through SDRT graphs, increasing the
strengths or reversing the polarity of the sentiments, depending on
the type of the discourse relation that was linking two segments.

%In general, however, PDTB- and SDRT-based sentiment systems are much
%less common than RST-inspired solutions.  Because of this fact, we

STIMMT DIESE VORSCHAU NOCH ?? Given the dominance of RST-based methods, for the sake of comparison,
we replicated the linear combination approach of \newcite{Wang:13} and
also reimplemented the DDR and R2N2 systems of~\newcite{Bhatia:15}.
Furthermore, to see how these techniques would perform in comparison
with much simpler baselines, we additionally created two methods that
predicted the polarity of a message by only considering its last or
topmost nucleus EDU (henceforth \textsc{Last} and \textsc{Root}), and
also estimated the results of our original LBA classifier without any
discourse-related modifications (henceforth \textsc{No-Discourse}).
